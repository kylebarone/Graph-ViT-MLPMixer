dataset: CIFAR10
num_workers: 2
model:
  gMHA_type: MLPMixer
  gnn_type: GINEConv
  nlayer_gnn: 4
  nlayer_mlpmixer: 4
train:
  lr_patience: 50
  epochs: 20
metis:
  n_patches: 32
pos_enc:
  lap_dim: 8
